{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLyFTw5nbYkQ"
      },
      "source": [
        "# Text classification with Transformer\n",
        "\n",
        "**Author:** [Apoorv Nandan](https://twitter.com/NandanApoorv)<br>\n",
        "**Date created:** 2020/05/10<br>\n",
        "**Last modified:** 2024/01/18<br>\n",
        "**Description:** Implement a Transformer block as a Keras layer and use it for text classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB-kva8LbYkW"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FcMyPJOabYkX"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import ops\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXzbmqlDbYkZ"
      },
      "source": [
        "## Implement a Transformer block as a layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "F-oSKCT1bYka"
      },
      "outputs": [],
      "source": [
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super().__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = keras.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPUEi6UBbYkb"
      },
      "source": [
        "## Implement embedding layer\n",
        "\n",
        "Two  embedding layers, one for tokens, one for token index (positions)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IoKuHivubYkb"
      },
      "outputs": [],
      "source": [
        "class TokenAndPositionEmbedding(layers.Layer):\n",
        "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
        "        super().__init__()\n",
        "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
        "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
        "\n",
        "    def call(self, x):\n",
        "        maxlen = ops.shape(x)[-1]\n",
        "        positions = ops.arange(start=0, stop=maxlen, step=1)\n",
        "        positions = self.pos_emb(positions)\n",
        "        x = self.token_emb(x)\n",
        "        return x + positions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kokMzV0xbYkc"
      },
      "source": [
        "## Download and prepare dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqMHyNv7bYkd",
        "outputId": "69c1d288-5477-46d8-e0b5-67acee7a83d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ok lar joke wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>free entri wkli comp win fa cup final tkt st m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>u dun say earli hor u c alreadi say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>nah think goe usf live around though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>freemsg hey darl week word back! like fun stil...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   type                                            content\n",
              "0     0                              ok lar joke wif u oni\n",
              "1     1  free entri wkli comp win fa cup final tkt st m...\n",
              "2     0                u dun say earli hor u c alreadi say\n",
              "3     0               nah think goe usf live around though\n",
              "4     1  freemsg hey darl week word back! like fun stil..."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from nltk import PorterStemmer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "lbl = LabelEncoder()\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "en_stopwords = set(stopwords.words(\"english\"))\n",
        "def remove_stopwords(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_text = [word for word in word_tokens if word.lower() not in en_stopwords]\n",
        "    return ' '.join(filtered_text)\n",
        "\n",
        "df = pd.read_csv(\"./SMSCollection.txt\", sep='\\t')\n",
        "df.columns=[\"type\", \"content\"]\n",
        "cleaned_text = []\n",
        "for text in df.content:\n",
        "    text  = text.lower()\n",
        "    text  = re.sub('[^a-zA-Z!\\?]', ' ', text)\n",
        "    text  = re.sub('\\s{2,}', ' ', text)\n",
        "    text  = remove_stopwords(text)\n",
        "    words = [ps.stem(word) for word in word_tokenize(text)]\n",
        "    text  = TreebankWordDetokenizer().detokenize(words)\n",
        "    cleaned_text.append(text)\n",
        "\n",
        "df['content'] = cleaned_text\n",
        "\n",
        "df.replace('', np.nan, inplace=True)\n",
        "df.replace(' ', np.nan, inplace=True)\n",
        "df.dropna(axis=0,inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "df['type'] = lbl.fit_transform(df['type'])\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 5062 entries, 0 to 5570\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   type     5062 non-null   int32 \n",
            " 1   content  5062 non-null   object\n",
            "dtypes: int32(1), object(1)\n",
            "memory usage: 98.9+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['ham', 'spam'], dtype=object)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lbl.classes_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "77"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "maxlen = max([len(word_tokenize(i)) for i in list(df.content)])\n",
        "maxlen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'ok lar joke wif u oni'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(df.content)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_size = 20000  # Only consider the top 20k words\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer \n",
        "from tensorflow.keras.utils import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token='OOV')\n",
        "tokenizer.fit_on_texts(df.content)\n",
        "\n",
        "\n",
        "tokenizer_path = 'tokenizer.json'\n",
        "tokenizer_json = tokenizer.to_json()\n",
        "with open(tokenizer_path, 'w', encoding='utf-8') as f:\n",
        "    f.write(tokenizer_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenized_content =pad_sequences(tokenizer.texts_to_sequences(df.content), maxlen=maxlen, padding='post', truncating='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvkv3u-_ddj7",
        "outputId": "7b625991-63e3-421c-8c26-9f10a356f0d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4555 Training sequences\n",
            "507 Validation sequences\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tokenized_content,list(df.type),test_size=0.1)\n",
        "\n",
        "print(len(X_train), \"Training sequences\")\n",
        "print(len(X_test), \"Validation sequences\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-VTzjjpbYke"
      },
      "source": [
        "## Create classifier model using transformer layer\n",
        "\n",
        "Transformer layer outputs one vector for each time step of our input sequence.\n",
        "Here, we take the mean across all time steps and\n",
        "use a feed forward network on top of it to classify text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "G09NUQyabYke"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\Moatasem\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "embed_dim = 32  # Embedding size for each token\n",
        "num_heads = 2  # Number of attention heads\n",
        "ff_dim = 32  # Hidden layer size in feed forward network inside transformer\n",
        "\n",
        "inputs = layers.Input(shape=(maxlen,))\n",
        "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
        "x = embedding_layer(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "x = transformer_block(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "x = layers.Dense(20, activation=\"relu\")(x)\n",
        "x = layers.Dropout(0.1)(x)\n",
        "outputs = layers.Dense(2, activation=\"softmax\")(x)\n",
        "\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf1K4W4BbYkf"
      },
      "source": [
        "## Train and Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bL03rlkqbYkf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 42ms/step - accuracy: 0.8523 - loss: 0.3839 - val_accuracy: 0.8935 - val_loss: 0.2073\n",
            "Epoch 2/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.9020 - loss: 0.2187 - val_accuracy: 0.9744 - val_loss: 0.0922\n",
            "Epoch 3/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 38ms/step - accuracy: 0.9734 - loss: 0.0967 - val_accuracy: 0.9921 - val_loss: 0.0445\n",
            "Epoch 4/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 38ms/step - accuracy: 0.9932 - loss: 0.0247 - val_accuracy: 0.9822 - val_loss: 0.0469\n",
            "Epoch 5/5\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.9970 - loss: 0.0160 - val_accuracy: 0.9941 - val_loss: 0.0270\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "history = model.fit(\n",
        "    np.array(X_train), np.array(y_train), batch_size=50, epochs=5, validation_data=(np.array(X_test), np.array(y_test))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('transformer.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train shape: (4555, 77)\n",
            "y_train shape: (4555,)\n",
            "X_test shape: (507, 77)\n",
            "y_test shape: (507,)\n"
          ]
        }
      ],
      "source": [
        "print(f'X_train shape: {np.array(X_train).shape}')\n",
        "print(f'y_train shape: {np.array(y_train).shape}')\n",
        "print(f'X_test shape: {np.array(X_test).shape}')\n",
        "print(f'y_test shape: {np.array(y_test).shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.argmax(model(X_test)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "text_classification_with_transformer",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
